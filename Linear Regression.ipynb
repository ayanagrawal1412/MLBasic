{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression\n",
    "\n",
    "## Math\n",
    "\n",
    "|Symbol| Meaning|\n",
    "|--|--|\n",
    "|$x$ | feature|\n",
    "|$y$ | target|\n",
    "|$x^{(i)}$ | i<sup>th</sup> training example in case of Single Variable Linear Regression|\n",
    "|$\\hat y$ | estimated value of target|\n",
    "|$m$|No. of training examples|\n",
    "|$n$|No. of features in a single training example|\n",
    "|$x^{(i)}_j$ | j<sup>th</sup> feature of i<sup>th</sup> training example for Multiple Variable Linear Regression|\n",
    "|$\\mathbf x^{(i)}$ | i<sup>th</sup> training example for Multiple Variable Linear Regression represented as a vector|\n",
    "\n",
    "Note on notations: Capital bold face used to denote Matrix (or 2d arrays); small bold face symbol to denote a vector (or 1d array) and when used in matrix equations, can be used to denote a single column matrix."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**Model Representation** (sometimes called a hypothesis function):\n",
    "\n",
    "For a single featured training set:\n",
    "\\begin{align*} f(x^{(i)}) &= \\hat {y^{(i)}} \\\\\n",
    "f_{wb}(x^{(i)}) &= wx^{(i)} + b \\tag{1} \\end{align*}\n",
    "\n",
    "**Mean Squared Error (MSE)** Cost\n",
    "\\begin{align*}J &= \\sum_{i=1}^{m} \\frac{(f(x^{(i)})-y^{(i)})^2}{2m} \\tag{2} \\\\\n",
    "J_{wb} &= \\sum_{i=1}^{m} \\frac{(wx^{(i)} + b-y^{(i)})^2}{2m} \\tag{3} \\end{align*}\n",
    "\n",
    "To find $w$ and $b$, and thus the estimator function we must minimize cost ( $J$ ) wrt $w$ and $b$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For an intuition for Mean Squared Error Cost function consider this - to approximate a bunch of numbers by a single number we often cite the data's average or arithmetic mean. \n",
    "\n",
    "**Mean is the point from which the arithmetic sum of differences from all the numbers is zero.**\n",
    "\n",
    "Let $\\bar x$ denote the mean of a set of scalar $x^{(i)}$\n",
    "\n",
    "$$ \\sum_{i=1}^{m} (x^{(i)}-\\bar x) = \\sum_{i=1}^{m}x^{(i)} - m\\bar x = \\sum_{i=1}^{m}x^{(i)}- \\sum_{i=1}^{m}x^{(i)} = 0$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "If we were to find a number, lets say $\\mu$, sum of squares of differences from which of all the numbers in a dataset, is to be minimized, we'd see that that number, is in fact, the mean.\n",
    "To minimize $$ \\sum_{i=1}^{m} (x^{(i)}-\\mu)^2$$\n",
    "lets take the derivative of the above term wrt $\\mu$ and equate it to zero.\n",
    "\\begin{align*}\\dfrac{d}{d \\mu} \\left(\\sum_{i=1}^{m} (x^{(i)}-\\mu)^2\\right)=0 \\\\\n",
    "\\sum_{i=1}^{m} \\left(2(x^{(i)}-\\mu) \\cdot \\frac{d(x^{(i)}-\\mu)}{d \\mu}\\right) = 0 \\\\\n",
    "-2 \\sum_{i=1}^{m} (x^{(i)}-\\mu) = 0 \\\\\n",
    "\\sum_{i=1}^{m} (x^{(i)}-\\mu) = 0 \\\\\n",
    "\\Rightarrow \\mu = \\bar x\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**Thus (arithmetic) mean is the point, sum of squares of differences from which of all the numbers in a dataset, is minimum.**\n",
    "\n",
    "**Related fact - median is the point, sum of absolute differences (or distances) from which of all the numbers in a dataset is minimum.**\n",
    "\n",
    "Fun geometric fact - because arithmetic mean is that point sum of squares of differences from which is minimum, if we're in a Eucleadian 2D plane, arithmetic mean of the x coordinates of the points gives us a number, sum of squares of differences of x coordinates of all the points from this number is minimum, and similarly the mean of y coordinates gives us a similar number. Together the arithmetic means of x and y coordinates is in fact the coordinates of the point where both the sums ie of squares of x differences and that of squares of y differences are minimum. Thus for this point the sum of these 2 sums would also be the minimum or this is the point on the plane from which sum of squares of distances (or differences) of all the points is minimum. \n",
    "\n",
    "Thus be it on a line or a plane and likewise in 3D or higher dimensions, arithmetic mean of coordinates of the points gives us the coordinates of the point from which sum of squared L2 Norms is minimum.\n",
    "\n",
    "On a line or 1D, L1 and L2 norm are same and median minimizes the sum of this from all the points but in case of 2D or higher dimensions, median only minimizes the L1 norm ie for 2D or higher dimensions, median of the coordinates of the points gives us the point from which L1 norm or sum of x and y distances over all points is minimized, ie not the sum of true geometric distances or L2 norm is minimized. The point that does that ie the point that minimizes L2 norm is called geometric median.\n",
    "\n",
    "**Thus arithmetic mean minimizes the sum of squared L2 norms, whereas geometric median minimizes the sum of L2 norms and the coordinate-wise median minimizes the sum of L1 norms.** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Coming back to the issue of cost function, we can think that just like the mean minimizes the sum of squared differences and zeroes out the sum of differences, by trying to best fit the data on a straight line ie while finding the equation of a line for the linear regression problem we try to pick a cost function that involves the sum of squared error terms and then try to minimize this hoping to net out or cancel the differences and most closely represent the data. We divide the sum of squared errors by the number of training examples to keep the cost bounded as it is expected that more the number of examples the greater is the sum of squared errors and dividing by $m$ helps us compare the costs between differently numbered training sets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also note that while trying to approximate a bunch of numbers on a number line by a single number, when we chose mean it both minimizes the sum of squared errors and makes the algebraic sum of errors go to zero.\n",
    "In case of finding the staight line fit to the data for linear regression (in a single variable/feature) problem, making the sum of errors to zero alone (which gives the below equation) doesn't give us a unique solution.\n",
    "$$\\sum_{i=1}^{m} (wx^{(i)} + b-y^{(i)})=0$$\n",
    "Above equation has 2 unknowns ($w$ and $b$) and thus we need something more to uniquely find both $w$ and $b$. Thus we need MSE cost as we'll see that minimizing the MSE cost gives both the above equation and the additional info required to find $w$ and $b$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From eq (2) note that $J$ is quadratic in both $w$ and $b$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{align*}\\frac {\\partial J}{\\partial w} &= \\sum_{i=1}^{m} \\frac {(wx^{(i)} + b-y^{(i)})x^{(i)}}{m}\\tag{4} \\\\\n",
    "\\frac {\\partial J}{\\partial b} &= \\sum_{i=1}^{m} \\frac {(wx^{(i)} + b-y^{(i)})}{m} \\tag{5} \\end{align*}\n",
    "\n",
    "Equating both the partial derivatives to zero we get:\n",
    "\\begin{align*} \\sum_{i=1}^{m} \\left((wx^{(i)} + b-y^{(i)})x^{(i)}\\right) &=0 \\tag{6} \\\\\n",
    "\\sum_{i=1}^{m} (wx^{(i)} + b-y^{(i)})&=0 \\tag{7} \\end{align*}\n",
    "\n",
    "Eq (7) is the one we wrote earlier when we set out to make the sum of error terms zero which we see now is 1 of the results of minimizing the MSE cost function. Together the above 2 equations give us the sufficient information info to solve for 2 unkowns $w$ and $b$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For **Multiple Variable Linear Regression**, vectorially the equations are:\n",
    "\\begin{align*} f^{(i)} &= \\mathbf w \\cdot \\mathbf x^{(i)} + b \\tag{8}\\\\\n",
    "J &= \\sum_i \\frac {(f^{(i)}-y^{(i)})^2}{2m} \\tag{9}\\\\\n",
    "\\frac {\\partial J}{\\partial \\mathbf w} &= \\sum_i \\frac{(f^{(i)}-y^{(i)})\\mathbf x^{(i)}}{m} \\tag{10}\\\\\n",
    "\\frac {\\partial J}{\\partial b} &= \\sum_i \\frac{(f^{(i)}-y^{(i)})}{m} \\tag{11} \\end{align*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the training data set is given as a matrix where every training example is on a separate row, and j<sup>th</sup> column in a matrix represents the j<sup>th</sup> feature in every example, we can write following matrix equations:\n",
    "\\begin{align*} \\mathbf f &= \\mathbf X \\mathbf w + b \\tag{12} \\\\\n",
    "\\frac {\\partial J}{\\partial \\mathbf w} &= \\frac {\\mathbf X^T(\\mathbf f -\\mathbf y)}{m} \\tag{13} \\end{align*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In some contexts, $\\mathbf w$ and $b$ are combined in a single parameter $ \\boldsymbol {\\theta} $ with b as the first component of $\\boldsymbol{\\theta} $ and the remaining components coming from $\\mathbf w$. Here the feature matrix must be prefixed with a column containing all 1(s). For such a notation, the following holds:\n",
    "$$\\mathbf f = \\mathbf X\\boldsymbol{\\theta}$$\n",
    "Optimizing $J$:\n",
    "\\begin{align*} \\frac {\\partial J}{\\partial \\boldsymbol{\\theta}} &=0 \\\\\n",
    "\\frac {\\mathbf X^T(\\mathbf X\\boldsymbol{\\theta} - \\mathbf y)}{m} &= 0\\\\\n",
    "\\mathbf X^T \\mathbf X\\boldsymbol{\\theta} &= \\mathbf X^T\\mathbf y\\\\\n",
    "\\boldsymbol{\\theta} &= (\\mathbf X^T \\mathbf X)^{-1}\\mathbf X^T\\mathbf y \\tag{14} \\end{align*}\n",
    "\n",
    "Above eq known as **normal equation** gives the exact solution of linear regression."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Descent and cost plots wrt parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even though we have an analytical solution for Linear Regression, we'll see that an iterative algorithm such as Gradient Descent (with proper techniques like normalization) often would help us get closer to acceptable solutions faster than normal equation. Also this approach works for other types of regression and classification where we dont have an analytical solution. So its recommended to almost never use normal equation method in any real world ML problem ourselves. (Its possible some of the libraries might use normal equation internally) - Given advice is from Andrew Ng. Need some more research to verify some of this."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Going back to the single variable Linear Regression problem, $J$ is quadratic in both $w$ and $b$ (eq (3)) and when plotted forms an upward facing bowl like shape ($w$ and $b$ being in the xy plane and $J$ along the z axis that's pointing upwards). Since $J$ is quadratic in both $w$ and $b$, keeping either of $w$ or $b$ constant and plotting $J$ vs the other produces an upwards facing parabola. Expanding the terms in eq (3) gives:\n",
    "\n",
    "\\begin{align*} J &= \\sum \\frac{(x^{(i)})^2w^2 + b^2 + (y^{(i)})^2 + 2x^{(i)}wb - 2y^{(i)}b - 2x^{(i)}y^{(i)}w} {2m} \\\\\n",
    "\\\\\n",
    "&= \\frac{\\displaystyle{\\left(\\sum({x^{(i)}})^2\\right) w^2 +\\ \\left(2\\sum x^{(i)} \\right) wb + mb^2 - \\left(2\\sum x^{(i)}y^{(i)} \\right)w - \\left(2\\sum y^{(i)} \\right) b + \\sum(y^{(i)})^2}} {2m} \\end{align*}\n",
    "\n",
    "Now since  $\\displaystyle{m\\sum({x^{(i)}})^2 - \\left(\\sum x^{(i)}\\right)^2 > 0}$, for any set of real $x^{(i)}$, above expression when equated to any value would give the equation of an ellipse (in the variables $w$ and $b$) and thus we can say that the contour plots of cost are ellipses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Going back to Gradient Descent, the objective is to find a path from an initial cost towards a direction which leads to the steepest slope or descent. We keep on updating the parameters $w$ and $b$ going in the direction of steepest descent with a learning rate $\\alpha$ till the successive descents stop providing an appreciable cost reduction or till we reach a minima for $J$ which is a function of $w$ and $b$. The minima we reach through a Gradient Descent is a local minima but in case of linear regression it is also a global one.\n",
    "\n",
    "Need to keep $\\alpha$ small enough to not overshoot cost in successive iterations but big enough to not slow down the convergence to the solution.\n",
    "\n",
    "Gradient Descent Algo:\n",
    "\\begin{align*} w &\\to w - \\alpha \\frac {\\partial J}{\\partial w} \\\\\n",
    "b &\\to b - \\alpha \\frac {\\partial J}{\\partial b} \\end{align*} "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NumPy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most popular library for Linear Algebra ie for doing maths on vectors and matrices. Vectors represented as 1d arrays and Matrices as 2d arrays, while NumPy supports higher dimensioned arrays as well. Total number of dimensions (also called **axes** in NumPy terminology) is called the **rank** of the NumPy array. A 2d np array can be thought of as an array of (m) arrays each of which in turn contains (n) scalars. And, we say (m,n) is the **shape** (which is basically a tuple in Python) of this 2d array. Rank here is 2. Thus len of shape is rank. And m is the 1st axis and n is the last axis. When such an np array is printed, it's shown as a grid of m rows and n columns.\n",
    "\n",
    "### Some properties/syntax with examples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 2 3 4 5]\n",
      "shape of a: (5,)\n",
      "rank of a: 1\n",
      "data type of a: <class 'numpy.ndarray'>\n",
      "data type of elements of a: int32\n"
     ]
    }
   ],
   "source": [
    "a = np.array([1,2,3,4,5])\n",
    "print(a)\n",
    "print(f'shape of a: {a.shape}')\n",
    "print(f'rank of a: {len(a.shape)}')\n",
    "print(f'data type of a: {type(a)}')\n",
    "print(f'data type of elements of a: {a.dtype}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 2. 3. 4.]\n",
      " [5. 6. 7. 8.]]\n",
      "shape of b: (2, 4)\n",
      "rank of b: 2\n",
      "data type of elements of b: float64\n"
     ]
    }
   ],
   "source": [
    "b= np.array([[1.0,2,3,4],[5,6,7,8]])\n",
    "print(b)\n",
    "print(f'shape of b: {b.shape}')\n",
    "print(f'rank of b: {len(b.shape)}')\n",
    "print(f'data type of elements of b: {b.dtype}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All the elements of np array must be of the same data type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.0\n",
      "shape of c: ()\n",
      "rank of c: 0\n",
      "data type of elements of c: float64\n",
      "type of c: <class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "c=np.array(3.0)\n",
    "print(c)\n",
    "print(f'shape of c: {c.shape}')\n",
    "print(f'rank of c: {len(c.shape)}')\n",
    "print(f'data type of elements of c: {c.dtype}')\n",
    "print(f'type of c: {type(c)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*An np array can also have 0 dimensions or rank = 0 but can still contain a scalar value*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(3) == c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*While checking equality, it checks for value not the data type*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0.])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.zeros(2) # 1d array of 2 elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0.])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.zeros((2,)) #Passing a scalar or a tuple with length 1 as a parameter produces same result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[0. 0.]\n",
      "  [0. 0.]\n",
      "  [0. 0.]\n",
      "  [0. 0.]]\n",
      "\n",
      " [[0. 0.]\n",
      "  [0. 0.]\n",
      "  [0. 0.]\n",
      "  [0. 0.]]\n",
      "\n",
      " [[0. 0.]\n",
      "  [0. 0.]\n",
      "  [0. 0.]\n",
      "  [0. 0.]]]\n"
     ]
    }
   ],
   "source": [
    "d=np.zeros((3,4,2))\n",
    "print(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.arange(10) # accepts only an integer not a tuple. Produces 1d array of that many elements starting from 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.78745649, 0.22815109, 0.04346343, 0.60629973, 0.56631849,\n",
       "       0.68268549, 0.53360991, 0.50686169, 0.55880697, 0.80054397])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.rand(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "random.rand also accepts an integer as a parameter (not a tuple) and produces array of given length with value [0,1). random.random_sample accepts a tuple too as a parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.7583801 , 0.93510172, 0.88793483, 0.48953159, 0.91958823,\n",
       "       0.5794756 , 0.3711545 , 0.63061935, 0.68224789, 0.69938625])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.random_sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.34719564, 0.66872739],\n",
       "       [0.02564214, 0.12422266],\n",
       "       [0.68309453, 0.55549225],\n",
       "       [0.58875464, 0.0978877 ],\n",
       "       [0.91238643, 0.98325602]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.random_sample((5,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Like lists in Python we can slice an np array with an identical syntax `a[start:stop:step]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 4])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[1:4:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5. 6. 7. 8.]\n",
      "[5. 6. 7. 8.]\n",
      "[2. 6.]\n"
     ]
    }
   ],
   "source": [
    "print(b[1,:]) # from row number 1 pick all columns\n",
    "print(b[1]) # results in same as above\n",
    "print(b[:,1]) # from every row, pick column number 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both the above produce 1d arrays from 2d array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2.]\n",
      " [6.]]\n"
     ]
    }
   ],
   "source": [
    "print(b[:,1:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice diff btw above 2 results. When range is given in the slice it preserves shape, when an explicit number is given, it flattens the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1],\n",
       "       [2],\n",
       "       [3],\n",
       "       [4],\n",
       "       [5]])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e=np.array([[1],[2],[3],[4],[5]])\n",
    "e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 3, 4, 5])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e[:,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also get above using **reshape**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 3, 4, 5])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f=e.reshape((5,))\n",
    "f"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and get back to original by this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1],\n",
       "       [2],\n",
       "       [3],\n",
       "       [4],\n",
       "       [5]])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f.reshape((5,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While providing the expected shape parameter in the reshape method, we can put a -1 in exactly 1 of the places and it figures out the right shape automatically"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1],\n",
       "       [2],\n",
       "       [3],\n",
       "       [4],\n",
       "       [5]])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f.reshape((-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 3, 4, 5])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e.reshape((-1,))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Broadcasting\n",
    "\n",
    "Quite elegant functionality of NumPy arrays. Helps to do arithmetic between arrays of different shapes. A simple arithmetic like additiion or multiplication of 1 np array with another object should require the other object also to be an np array of exactly same shape because arithmetic is done element wise between these np arrays. But broadcasting relaxes this constraint and expands (think of it as by copying) the axis of length 1 in 1 array to match the size of the corresponding axis in the 2<sup>nd</sup> array or adds more axes in the smaller of the 2 arrays or even scalars so that we get 2 arrays having the same number of axes and with same lengths giving us the same number of elements in both arrays to facilitate the element-wise arithmetic.\n",
    "\n",
    "Only 2 imp rules to remember abt broadcasting:\n",
    "1. It compares shapes from the right most axis of the 2 arrays moving leftward until we reach the end for 1 of the arrays.\\\n",
    "So if a.shape = (5,4,2) \\\n",
    "and b.shape = (4,2) \\\n",
    "Then we can do arithmetic with a and b, because all (the 2) dimensions of b are same as the last 2 dimensions of a. But if b's shape were (3,4,2) then it wouldn't have worked because 3 is not equal to 5.\n",
    "\n",
    "2. Also for a pair of dimensions to be compatible they either have to be same or 1 of those 2 need to be 1.\\\n",
    "So if b.shape were (4,1) then also a and b would be compatible.\\\n",
    "It would have also worked if shape of b had been (2,)\n",
    "\n",
    "Eg where both the arrays in an arithmetic expression are broadcasted: if a.shape = (8,1,6,1) and b.shape = (7,1,5), then the result.shape = (8,7,6,5).\\\n",
    "Some egs in code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4, 5],\n",
       "       [6, 7],\n",
       "       [8, 9]])"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.array([[1,2],[3,4],[5,6]])\n",
    "a+3 # array (shape (3,2)) and scalar --> shape (3,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2, 3],\n",
       "       [5, 6],\n",
       "       [8, 9]])"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b= np.array([[1],[2],[3]])\n",
    "a+b # shapes (3,2) and (3,1) --> shape (3,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 5,  7],\n",
       "       [ 7,  9],\n",
       "       [ 9, 11]])"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = np.array([4,5])\n",
    "a+c # shapes (3,2) and (2,) --> shape (3,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (3,2) (3,) ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[138], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m d \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([\u001b[38;5;241m4\u001b[39m,\u001b[38;5;241m5\u001b[39m,\u001b[38;5;241m6\u001b[39m])\n\u001b[1;32m----> 2\u001b[0m \u001b[43ma\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43md\u001b[49m \u001b[38;5;66;03m#shapes (3,2) and (3,) --> error\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: operands could not be broadcast together with shapes (3,2) (3,) "
     ]
    }
   ],
   "source": [
    "d = np.array([4,5,6])\n",
    "a+d #shapes (3,2) and (3,) --> error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8, 7, 6, 5)"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.ones((8,1,6,1))\n",
    "b = np.ones((7,1,5))\n",
    "(a+b).shape #both arrays are broadcasted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dot Product\n",
    "\n",
    "`np.dot(a,b)` If $a$ and $b$ are both 1d arrays it is exactly like a dot product between 2 vectors ($a$ and $b$ must have same shape ie same number of components) ie a sum of product of their respective components or sum product in short. Also either $a$ or $b$ or both of these parameters can be scalars too in which case it behaves like a multiplication of a vector with scalar or just a simple product of 2 scalars (when both are scalars)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n",
      "<class 'numpy.int32'>\n"
     ]
    }
   ],
   "source": [
    "dot_product_scalars = np.dot(3,4)\n",
    "print(dot_product_scalars)\n",
    "print(type(dot_product_scalars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n",
      "<class 'numpy.int32'>\n"
     ]
    }
   ],
   "source": [
    "dot_product_0d_arrays = np.dot(np.array(3),np.array(4))\n",
    "print(dot_product_0d_arrays)\n",
    "print(type(dot_product_0d_arrays))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.0\n",
      "<class 'numpy.float64'>\n"
     ]
    }
   ],
   "source": [
    "a=np.array([3,4])\n",
    "b=np.array([1.,0])\n",
    "dot_product_vectors = np.dot(a,b)\n",
    "print(dot_product_vectors)\n",
    "print(type(dot_product_vectors))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6 8]\n"
     ]
    }
   ],
   "source": [
    "print(np.dot(a,2)) #dot product between vector and scalar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "shapes (2,) and (1,) not aligned: 2 (dim 0) != 1 (dim 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[75], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdot\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mValueError\u001b[0m: shapes (2,) and (1,) not aligned: 2 (dim 0) != 1 (dim 0)"
     ]
    }
   ],
   "source": [
    "np.dot(a,np.array([2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Broadcasting isn't meant for 'dot', it's meant for simple arithmetic like addition, subtraction , multiplication etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([6, 8])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a*np.array([2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. If $a$ is an N-D array and $b$ is a 1-D array, it is a sum product over the last axis of $a$ and $b$.**\\\n",
    "Above property implies that if $a$ is a 2d array then the result is exactly like a matrix multiplication in maths, as if $b$ were a single column matrix.\n",
    "\n",
    "Thus when we need to multiply a (multi-row, multi-column) matrix with a 'single column' matrix, instead of representing  matrix multiplication between two 2d arrays in NumPy, for simplicity, we can just show it as a dot product of multi-row, multi-column matrix (2d array) with a 'single column' matrix represented as a 1d array (although technically a matrix by definition is always a 2d object whether it contains multiple columns or not) and then interpret the result of the dot also as a 'single column' matrix.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X:\n",
      "[[1 2]\n",
      " [3 4]\n",
      " [5 6]]\n",
      "w:[3 5]\n",
      "X dot w: [13 29 45]\n"
     ]
    }
   ],
   "source": [
    "X=np.array([[1,2],[3,4],[5,6]])\n",
    "w=np.array([3,5])\n",
    "print(f'X:\\n{X}')\n",
    "print(f'w:{w}')\n",
    "print(f'X dot w: {np.dot(X,w)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X:\n",
      "[[1 2]\n",
      " [3 4]\n",
      " [5 6]]\n",
      "W:\n",
      "[[3]\n",
      " [5]]\n",
      "XW:\n",
      "[[13]\n",
      " [29]\n",
      " [45]]\n"
     ]
    }
   ],
   "source": [
    "W= np.array([[3],[5]])\n",
    "print(f'X:\\n{X}')\n",
    "print(f'W:\\n{W}')\n",
    "print(f'XW:\\n{X@W}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*`@` is the operator for matrix multiplication. `a@b` is shorthand for `np.matmul(a,b)`.*\\\n",
    "**2. Incidentally np.dot between two 2d arrays (two matrices) produces the same result as matmul although matmul or `@` is preferred**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dot:\n",
      "[[13]\n",
      " [29]\n",
      " [45]]\n",
      "matmul:\n",
      "[[13]\n",
      " [29]\n",
      " [45]]\n"
     ]
    }
   ],
   "source": [
    "print(f'dot:\\n{np.dot(X,W)}')\n",
    "print(f'matmul:\\n{np.matmul(X,W)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Actually if both $a$ and $b$ are np arrays of ranks between 1 and 2 or when 1 of the arrays has rank 1 and the other has a rank even greater than 2 then both the operators produce the same result. Matmul doesn't support any of its operands to be scalar or even 0d np array so if operands could possibly be scalars then must use dot instead of matmul*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X dot w: [13 29 45]\n",
      "X matmul w: [13 29 45]\n"
     ]
    }
   ],
   "source": [
    "print(f'X dot w: {np.dot(X,w)}')\n",
    "print(f'X matmul w: {np.matmul(X,w)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dot_product_vectors: 3.0\n",
      "matmul_vectors: 3.0\n"
     ]
    }
   ],
   "source": [
    "a=np.array([3,4])\n",
    "b=np.array([1.,0])\n",
    "print(f'dot_product_vectors: {np.dot(a,b)}')\n",
    "print(f'matmul_vectors: {np.matmul(a,b)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "matmul: Input operand 1 does not have enough dimensions (has 0, gufunc core with signature (n?,k),(k,m?)->(n?,m?) requires 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[92], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m c\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39marray([\u001b[38;5;241m3\u001b[39m])\n\u001b[0;32m      2\u001b[0m d\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39marray(\u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m----> 3\u001b[0m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmatmul\u001b[49m\u001b[43m(\u001b[49m\u001b[43mc\u001b[49m\u001b[43m,\u001b[49m\u001b[43md\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mValueError\u001b[0m: matmul: Input operand 1 does not have enough dimensions (has 0, gufunc core with signature (n?,k),(k,m?)->(n?,m?) requires 1)"
     ]
    }
   ],
   "source": [
    "c=np.array([3])\n",
    "d=np.array(2)\n",
    "np.matmul(c,d) # trying matmul with 0d array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "matmul: Input operand 1 does not have enough dimensions (has 0, gufunc core with signature (n?,k),(k,m?)->(n?,m?) requires 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[93], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmatmul\u001b[49m\u001b[43m(\u001b[49m\u001b[43mc\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mValueError\u001b[0m: matmul: Input operand 1 does not have enough dimensions (has 0, gufunc core with signature (n?,k),(k,m?)->(n?,m?) requires 1)"
     ]
    }
   ],
   "source": [
    "np.matmul(c,2) # trying matmul with scalar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3. If a is an N-D array and b is an M-D array (where M>=2), it is a sum product over the last axis of a and the second-to-last axis of b**\\\n",
    "1 example of above rule is when we multiply a 1d array with a 2d array:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a:\n",
      "[3 5]\n",
      "b:\n",
      "[[1 2 3]\n",
      " [4 5 6]]\n",
      "a dot b:\n",
      "[23 31 39]\n"
     ]
    }
   ],
   "source": [
    "a=np.array([3,5])\n",
    "b=np.array([[1,2,3],[4,5,6]])\n",
    "print(f'a:\\n{a}')\n",
    "print(f'b:\\n{b}')\n",
    "print(f'a dot b:\\n{np.dot(a,b)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above result looks similar to a matrix multiplication of a 'single row' matrix with a general (multi row) matrix. Thus although technically a matrix should be represented as a 2d array but when we need to multiply a 'single row' matrix with a general matrix, we can also simply show it as a dot product between a 1d array and 2d array and then interpret the result also as a 'single row' matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a matmul b:\n",
      "[23 31 39]\n"
     ]
    }
   ],
   "source": [
    "print(f'a matmul b:\\n{a@b}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also as noted before 3rd property, matmul gives the same result as well for arrays of ranks between 1 and 2.\\\n",
    "Also numerically speaking, we will get the same result (the shape would be different though) if the 1st np array were also a 2d array and there was a proper matrix(2d array) to matrix(2d array) multiplication."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A matmul b:\n",
      "[[23 31 39]]\n"
     ]
    }
   ],
   "source": [
    "A=np.array([[3,5]])\n",
    "print(f'A matmul b:\\n{A@b}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Thus both for dot and matmul, a 1d array as a left argument behaves like a single row matrix while as a right argument it behaves like a single column matrix.** The likeness is not absolute as the shape is different though had it actually been a 2d array."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Difference in results between matmul and dot\n",
    "If either of `a` or `b` has a rank greater than 2 then matmul assumes it to be an array (of shape sans the last 2 indices of the original array's shape) of matrices. Each of the operands now can be thought of as either an array of matrices or just a matrix. The case here is similar to doing arithmetic like addition or multiplication between different arrays or between scalars and arrays and thus matmul applies rules of broadcasting to resolve the difference if one operand has a different shape of array of matrices than the other.\\\n",
    "For eg:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with remapped shapes [original->remapped]: (3,4,2)->(3,newaxis,newaxis) (5,2,6)->(5,newaxis,newaxis)  and requested shape (4,6)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[120], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m a \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mones([\u001b[38;5;241m3\u001b[39m,\u001b[38;5;241m4\u001b[39m,\u001b[38;5;241m2\u001b[39m])\n\u001b[0;32m      2\u001b[0m b \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mones([\u001b[38;5;241m5\u001b[39m,\u001b[38;5;241m2\u001b[39m,\u001b[38;5;241m6\u001b[39m])\n\u001b[1;32m----> 3\u001b[0m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmatmul\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mshape\n",
      "\u001b[1;31mValueError\u001b[0m: operands could not be broadcast together with remapped shapes [original->remapped]: (3,4,2)->(3,newaxis,newaxis) (5,2,6)->(5,newaxis,newaxis)  and requested shape (4,6)"
     ]
    }
   ],
   "source": [
    "a = np.ones([3,4,2])\n",
    "b = np.ones([5,2,6])\n",
    "np.matmul(a,b).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Think of `a` as an array of 3 elements each of which is a matrix and `b` as an array of 5 elements each of which is also a matrix. Now the shapes of matrices in these 2 arrays agree for a successful matrix multiplication ie shapes of matrices in `a` which is (4,2) agree with shapes of matrices in `b` which is (2,6) for a proper matrix multiplication but just like we can't multiply an array of shape (3,) with an array of shape (5,), it will throw an error. However if `b`'s shape were (5,3,2,6) then it would have worked because arrays of shapes (3,) and (5,3) can have arithmetic done between according to broadcast rules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 3, 4, 6)"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b_ = np.ones([5,3,2,6])\n",
    "np.matmul(a,b_).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Whereas for dot, there actually is no broadcasting, and there actually is no requirement for a successful dot between 2 arrays of ranks greater than 2 other than that the last index of shape of 1st array (`a`) must match with the 2nd last index of shape of 2nd array (`b`). The final shape of the result is all the indices of shape of `a` except the last one followed by all indices of shape of `b` except the 2nd last one.\\\n",
    "For eg:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a.shape:(3, 4, 2)\n",
      "b.shape:(5, 2, 6)\n",
      "b_.shape:(5, 3, 2, 6)\n",
      "np.dot(a,b).shape:(3, 4, 5, 6)\n",
      "np.dot(a,b_).shape:(3, 4, 5, 3, 6)\n"
     ]
    }
   ],
   "source": [
    "print(f'a.shape:{a.shape}')\n",
    "print(f'b.shape:{b.shape}')\n",
    "print(f'b_.shape:{b_.shape}')\n",
    "print(f'np.dot(a,b).shape:{np.dot(a,b).shape}')\n",
    "print(f'np.dot(a,b_).shape:{np.dot(a,b_).shape}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
